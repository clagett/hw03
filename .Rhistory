load('nba2017-salary-points.RData')
test <- unclaimed[1:5,1]
library(dplyr)
library(readxl)
library(tidytext)
library(rvest)
library(stringr)
# This function inputs a certain date for
getWebsite <- function(date){
url = URLencode(paste0("https://www.nasdaq.com/earnings/earnings-calendar.aspx?date=",date))
page <- read_html(url)
results <- page %>%
html_nodes("#ECCompaniesTable td") %>% # Get all nodes of type "#ECCompaniesTable td"
html_text()
split <- as.data.frame(split(as.character(results), 1:9))
result <- split[-c(1,9)]
colnames(result) <- c("Name", "Expected Report Date", "Fiscal Quarter End",
"EPS Forcast", "# Forecasts", "Last Year Report Date", "Last Year EPS")
return(result)
}
mar14 <- getWebsite("2018-Mar-14")
View(mar14)
mar14 <- getWebsite("2018-Mar-14")
View(mar14$`EPS Forcast`)
sapply(mar14$`EPS Forcast`,
function(x) { gsub("[\r\n]", "", x) })
sapply(mar14$`EPS Forcast`,
function(x) { gsub("[\r\n\t", "", x) })
sapply(mar14$`EPS Forcast`,
function(x) { gsub("[\r\n\t"], "", x) })
sapply(mar14$`EPS Forcast`,
function(x) { gsub("[\r\n\t]", "", x) })
mar14.2 <- sapply(mar14$`EPS Forcast`,
function(x) { gsub("[\r\n\t]", "", x) })
mar14.2 <- sapply(mar14$`EPS Forcast`,
function(x) { gsub("[\r\n\t]", "", x) })
mar14.2
str(mar14.2)
as.numeric(mar14.2)
mar14.2 <- sapply(mar14$`EPS Forcast`, function(x){gsub("$", "", "")})
mar14.2
View(mar14.2)
str(mar14.2)
mar14 <- getWebsite("2018-Mar-14")
mar14$`EPS Forcast` <- str_replace_all(mar14$`EPS Forcast`), "[\r\n\t]" , "")
mar14$`EPS Forcast` <- str_replace_all(mar14$`EPS Forcast`), "[\r\n\t]", "")
mar14$`EPS Forcast` <- str_replace_all(mar14$`EPS Forcast`, "[\r\n\t]", "")
mar14$`EPS Forcast`
mar14$`EPS Forcast` <- str_replace_all(mar14$`EPS Forcast`, "$" , "")
mar14$`EPS Forcast`
# This function inputs a certain date for
getWebsite <- function(date){
url = URLencode(paste0("https://www.nasdaq.com/earnings/earnings-calendar.aspx?date=",date))
page <- read_html(url, stringsAsFactors = FALSE)
results <- page %>%
html_nodes("#ECCompaniesTable td") %>% # Get all nodes of type "#ECCompaniesTable td"
html_text()
split <- as.data.frame(split(as.character(results), 1:9))
result <- split[-c(1,9)]
colnames(result) <- c("Name", "Expected Report Date", "Fiscal Quarter End",
"EPS Forcast", "# Forecasts", "Last Year Report Date", "Last Year EPS")
return(result)
}
mar14 <- getWebsite("2018-Mar-14")
View(mar14)
str(mar14$`EPS Forcast`)
mar14 <- getWebsite("2018-Mar-14")
mar14[[`EPS Forcast`]])
mar14[[`EPS Forcast`]]
# This function inputs a certain date for
getWebsite <- function(date){
url = URLencode(paste0("https://www.nasdaq.com/earnings/earnings-calendar.aspx?date=",date))
page <- read_html(url)
results <- page %>%
html_nodes("#ECCompaniesTable td") %>% # Get all nodes of type "#ECCompaniesTable td"
html_text()
split <- as.data.frame(split(as.character(results), 1:9))
result <- split[-c(1,9)]
colnames(result) <- c("Name", "Expected Report Date", "Fiscal Quarter End",
"EPS Forcast", "# Forecasts", "Last Year Report Date", "Last Year EPS")
return(result)
}
mar14 <- getWebsite("2018-Mar-14")
View(mar14$`EPS Forcast`)
mar14[[`EPS Forcast`]]
grep("\\$[0-9.]+", mar14$`EPS Forcast`,value=TRUE)
grep("\\$[0-9.]+", mar14.2$`EPS Forcast`,value=TRUE)
str(mar14.2)
mar14 <- getWebsite("2018-Mar-14")
mar14.2 <- sapply(mar14$`EPS Forcast`,
function(x) { gsub("[\r\n\t]", "", x) })
grep("\\$[0-9.]+", mar14.2$`EPS Forcast`,value=TRUE)
str(mar14.2)
mar14$`EPS Forcast` <- str_replace_all(mar14["EPS Forecast"], "[\r\n\t]", "")
mar14["EPS Forecast"]
mar14["EPS Forecast",]
mar14[,"EPS Forecast"]
mar14[,EPS Forecast]
mar14.2["EPS Forecast",]
mar14.2["EPS Forecast"]
mar14.2["EPS Forcast"]
mar14 <- getWebsite("2018-Mar-14")
View(mar14$`EPS Forcast`)
source('C:/Users/mrcla/Desktop/scrape_nasdaq_earnings.R', echo=TRUE)
grep("\\$[0-9.]+", mar14$`EPS Forcast`,value=TRUE)
mar14.2 <- sapply(mar14$`EPS Forcast`,
function(x) { gsub("[\r\n\t]", "", x) })
View(mar14$`EPS Forcast`)
mar14 <- sapply(mar14$`EPS Forcast`,
function(x) { gsub("[\r\n\t]", "", x) })
View(mar14$`EPS Forcast`)
View(mar14)
mar14 <- getWebsite("2018-Mar-14")
View(mar14)
EPS <- data_frame(sapply(mar14$`EPS Forcast`,
function(x) { gsub("[\r\n\t]", "", x) }))
mar14.2 <- sapply(EPS, function(x){gsub("$", "", "")})
str(mar14.2)
mar14 <- getWebsite("2018-Mar-14")
EPS <- sapply(mar14$`EPS Forcast`,
function(x) { gsub("[\r\n\t]", "", x) })
mar14.2 <- sapply(EPS, function(x){gsub("$", "", "")})
str(mar14.2)
names(mar14.2)
EPS2 <- names(mar14.2)
EPS2
grep("\\$[0-9.]+", EPS2 ,value=TRUE)
grep("\\[0-9.]+", EPS2 ,value=TRUE)
grep("[0-9.]+", EPS2 ,value=TRUE)
str(EPS2)
data_frame(EPS2)
EPS3 <- data_frame(EPS2)
EPS4 <- grep("\\$[0-9.]+", EPS3 ,value=TRUE)
EPS4
EPS4 <- grep("\\$[0-9.]+", EPS4 ,value=TRUE)
EPS4
mar14.2
str(mar14.2)
?str
str(mar14.2, list.len = 500)
str(mar14.2, max.level = 50)
str(mar14.2, vec.length = 50)
EPS2 <- names(mar14.2)
str(EPS2)
test <- sapply(EPS2, function(x){gsub("$", "", "")})
test
View(test)
str(test)
names(test)
as.matrix(test)
test
rownames(test)
str(test)
mar14 <- getWebsite("2018-Mar-14")
View(mar14)
dates <- seq(as.Date('2018-03-10'),as.Date('2018-03-30'),by = 1)
weekdays <- dates[!weekdays(dates) %in% c('Saturday','Sunday')]
weekdays
format(weekdays, "%Y-%b-%d")
dates <- seq(as.Date('2018-03-10'),as.Date('2018-03-29'),by = 1)
weekdays <- dates[!weekdays(dates) %in% c('Saturday','Sunday')]
trading_days <- format(weekdays, "%Y-%b-%d")
getWebsite(trading_days)
View(getWebsite(trading_days))
source('C:/Users/mrcla/Desktop/scrape_nasdaq_earnings.R', echo=TRUE)
data_frame(getWebsite(trading_days))
data_frame(getWebsite(trading_days))
biglist <- data.frame()
for i in length(trading_days){
day <- getWebsite(i)
biglist <- rbind(biglist, day)
}
for i in length(trading_days){
day <- getWebsite(i)
biglist <- rbind(biglist, day)
}
biglist <- rbind(biglist, day)}
for i in length(trading_days){
day <- getWebsite(i)
biglist <- rbind(biglist, day)
}
for(i in length(trading_days)){
day <- getWebsite(i)
biglist <- rbind(biglist, day)
}
for(i in length(trading_days)){
day <- getWebsite(i)
biglist <- rbind(biglist, day)
biglist
}
?lapply
trading_days
trading_days <- as.character(format(weekdays, "%Y-%b-%d"))
for(i in length(trading_days)){
day <- getWebsite(i)
biglist <- rbind(biglist, day)
biglist
}
trading_days
lapply(trading_days, getWebsite)
View(lapply(trading_days, getWebsite))
View(sapply(trading_days, getWebsite))
data <- lapply(trading_days, getWebsite))
data <- lapply(trading_days, getWebsite)
ldply(data, rbind)
library(plyr)
ldply(data, rbind)
View(ldply(data, rbind))
View(bigdata)
bigdata <- ldply(data, rbind)
View(bigdata)
library(plyr)
library(dplyr)
library(stringr)
library(rvest)
dates <- seq(as.Date('2018-03-10'),as.Date('2018-03-29'),by = 1)
library(readxl)
weekdays <- dates[!weekdays(dates) %in% c('Saturday','Sunday')]
library(tidytext)
library(tidytext)
library(rvest)
library(stringr)
dates <- seq(as.Date('2018-03-10'),as.Date('2018-03-29'),by = 1)
weekdays <- dates[!weekdays(dates) %in% c('Saturday','Sunday')]
trading_days <- as.character(format(weekdays, "%Y-%b-%d"))
# This function inputs a certain date for stock earnings, returns it in a table
getWebsite <- function(date){
url = URLencode(paste0("https://www.nasdaq.com/earnings/earnings-calendar.aspx?date=",date))
page <- read_html(url)
results <- page %>%
html_nodes("#ECCompaniesTable td") %>% # Get all nodes of type "#ECCompaniesTable td"
html_text()
split <- as.data.frame(split(as.character(results), 1:9), stringsAsFactors = FALSE)
result <- split[-c(1,9)]
colnames(result) <- c("Name", "Expected Report Date", "Fiscal Quarter End",
"EPS Forcast", "# Forecasts", "Last Year Report Date", "Last Year EPS")
return(result)
}
data <- lapply(trading_days, getWebsite)
bigdata <- ldply(data, rbind)
clean_this <- function(column){
clean_hidden <- str_replace_all(column, "[\r\n\t]", "")
clean_dolla <- str_replace_all(as.character(clean_hidden), "\\$" , "")
clean_dolla[clean_dolla == "n/a"] <- NA
cleaned <- trimws(clean_dolla)
cleaned
}
# Adding EPS growth
cleaned_eps1 <- as.numeric(cleaned_data[,4])
cleaned_eps2 <- as.numeric(cleaned_data[,7])
EPS_growth <- rowSums(cbind(cleaned_eps1, -cleaned_eps2), na.rm=TRUE)
with_eps_growth <- cbind(cleaned_data, EPS_growth)
clean_this(bigdata)
View(clean_this(bigdata))
View(bigdata)
View(bigdata)
View(bigdata[c(1,2,7,4,5)])
dates <- seq(as.Date('2018-03-16'),as.Date('2018-04-27'),by = 1)
weekdays <- dates[!weekdays(dates) %in% c('Saturday','Sunday')]
trading_days <- as.character(format(weekdays, "%Y-%b-%d"))
# This function inputs a certain date for stock earnings, returns it in a table
getWebsite <- function(date){
url = URLencode(paste0("https://www.nasdaq.com/earnings/earnings-calendar.aspx?date=",date))
page <- read_html(url)
results <- page %>%
html_nodes("#ECCompaniesTable td") %>% # Get all nodes of type "#ECCompaniesTable td"
html_text()
split <- as.data.frame(split(as.character(results), 1:9), stringsAsFactors = FALSE)
result <- split[-c(1,9)]
colnames(result) <- c("Name", "Expected Report Date", "Fiscal Quarter End",
"EPS Forcast", "# Forecasts", "Last Year Report Date", "Last Year EPS")
return(result)
}
data <- lapply(trading_days, getWebsite)
View(bigdata[c(1,2,7,4,5)])
bigdata <- ldply(data, rbind)
dates <- seq(as.Date('2018-03-16'),as.Date('2018-04-27'),by = 1)
weekdays <- dates[!weekdays(dates) %in% c('Saturday','Sunday')]
trading_days <- as.character(format(weekdays, "%Y-%b-%d"))
View(trading_days)
data <- lapply(trading_days, getWebsite)
bigdata <- ldply(data, rbind)
View(bigdata[c(1,2,7,4,5)])
dates <- seq(as.Date('2018-03-16'),as.Date('2018-05-27'),by = 1)
weekdays <- dates[!weekdays(dates) %in% c('Saturday','Sunday')]
trading_days <- as.character(format(weekdays, "%Y-%b-%d"))
data <- lapply(trading_days, getWebsite)
bigdata <- ldply(data, rbind)
View(bigdata[c(1,2,7,4,5)])
dates <- seq(as.Date('2018-03-16'),as.Date('2018-06-27'),by = 1)
weekdays <- dates[!weekdays(dates) %in% c('Saturday','Sunday')]
nba <- read.csv("nba2017-roster.csv")
setwd("C:/Users/mrcla/Desktop/hw-stat133/hw03")
nba <- read.csv("nba2017-roster.csv")
View(nba)
knitr::opts_chunk$set(echo = TRUE, error=TRUE, fig.path = "images/")
